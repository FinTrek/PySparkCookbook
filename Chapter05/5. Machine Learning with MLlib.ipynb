{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PySpark Cookbook\n",
    "\n",
    "### Tomasz Drabas, Denny Lee\n",
    "#### Version: 0.1\n",
    "#### Date: 2/28/2018"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spark application\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>Current session?</th></tr><tr><td>1</td><td>None</td><td>pyspark</td><td>idle</td><td></td><td></td><td>âœ”</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession available as 'spark'.\n",
      "32561"
     ]
    }
   ],
   "source": [
    "import pyspark.sql.functions as func\n",
    "census_path = '../data/census_income.csv'\n",
    "\n",
    "census = spark.read.csv(\n",
    "    census_path\n",
    "    , header=True\n",
    "    , inferSchema=True\n",
    ")\n",
    "\n",
    "for col, typ in census.dtypes:\n",
    "    if typ == 'string':\n",
    "        census = census.withColumn(\n",
    "            col\n",
    "            , func.ltrim(func.rtrim(census[col]))\n",
    "        )\n",
    "census.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------------+------+------------+-------------+--------------------+-----------------+-------------+------------------+------+------------+------------+--------------+--------------+-----+\n",
      "|age|       workclass|fnlwgt|   education|education-num|      marital-status|       occupation| relationship|              race|   sex|capital-gain|capital-loss|hours-per-week|native-country|label|\n",
      "+---+----------------+------+------------+-------------+--------------------+-----------------+-------------+------------------+------+------------+------------+--------------+--------------+-----+\n",
      "| 39|       State-gov| 77516|   Bachelors|           13|       Never-married|     Adm-clerical|Not-in-family|             White|  Male|        2174|           0|            40| United-States|<=50K|\n",
      "| 50|Self-emp-not-inc| 83311|   Bachelors|           13|  Married-civ-spouse|  Exec-managerial|      Husband|             White|  Male|           0|           0|            13| United-States|<=50K|\n",
      "| 38|         Private|215646|     HS-grad|            9|            Divorced|Handlers-cleaners|Not-in-family|             White|  Male|           0|           0|            40| United-States|<=50K|\n",
      "| 53|         Private|234721|        11th|            7|  Married-civ-spouse|Handlers-cleaners|      Husband|             Black|  Male|           0|           0|            40| United-States|<=50K|\n",
      "| 28|         Private|338409|   Bachelors|           13|  Married-civ-spouse|   Prof-specialty|         Wife|             Black|Female|           0|           0|            40|          Cuba|<=50K|\n",
      "| 37|         Private|284582|     Masters|           14|  Married-civ-spouse|  Exec-managerial|         Wife|             White|Female|           0|           0|            40| United-States|<=50K|\n",
      "| 49|         Private|160187|         9th|            5|Married-spouse-ab...|    Other-service|Not-in-family|             Black|Female|           0|           0|            16|       Jamaica|<=50K|\n",
      "| 52|Self-emp-not-inc|209642|     HS-grad|            9|  Married-civ-spouse|  Exec-managerial|      Husband|             White|  Male|           0|           0|            45| United-States| >50K|\n",
      "| 31|         Private| 45781|     Masters|           14|       Never-married|   Prof-specialty|Not-in-family|             White|Female|       14084|           0|            50| United-States| >50K|\n",
      "| 42|         Private|159449|   Bachelors|           13|  Married-civ-spouse|  Exec-managerial|      Husband|             White|  Male|        5178|           0|            40| United-States| >50K|\n",
      "| 37|         Private|280464|Some-college|           10|  Married-civ-spouse|  Exec-managerial|      Husband|             Black|  Male|           0|           0|            80| United-States| >50K|\n",
      "| 30|       State-gov|141297|   Bachelors|           13|  Married-civ-spouse|   Prof-specialty|      Husband|Asian-Pac-Islander|  Male|           0|           0|            40|         India| >50K|\n",
      "| 23|         Private|122272|   Bachelors|           13|       Never-married|     Adm-clerical|    Own-child|             White|Female|           0|           0|            30| United-States|<=50K|\n",
      "| 32|         Private|205019|  Assoc-acdm|           12|       Never-married|            Sales|Not-in-family|             Black|  Male|           0|           0|            50| United-States|<=50K|\n",
      "| 40|         Private|121772|   Assoc-voc|           11|  Married-civ-spouse|     Craft-repair|      Husband|Asian-Pac-Islander|  Male|           0|           0|            40|             ?| >50K|\n",
      "| 34|         Private|245487|     7th-8th|            4|  Married-civ-spouse| Transport-moving|      Husband|Amer-Indian-Eskimo|  Male|           0|           0|            45|        Mexico|<=50K|\n",
      "| 25|Self-emp-not-inc|176756|     HS-grad|            9|       Never-married|  Farming-fishing|    Own-child|             White|  Male|           0|           0|            35| United-States|<=50K|\n",
      "| 32|         Private|186824|     HS-grad|            9|       Never-married|Machine-op-inspct|    Unmarried|             White|  Male|           0|           0|            40| United-States|<=50K|\n",
      "| 38|         Private| 28887|        11th|            7|  Married-civ-spouse|            Sales|      Husband|             White|  Male|           0|           0|            50| United-States|<=50K|\n",
      "| 43|Self-emp-not-inc|292175|     Masters|           14|            Divorced|  Exec-managerial|    Unmarried|             White|Female|           0|           0|            45| United-States| >50K|\n",
      "+---+----------------+------+------------+-------------+--------------------+-----------------+-------------+------------------+------+------------+------------+--------------+--------------+-----+\n",
      "only showing top 20 rows"
     ]
    }
   ],
   "source": [
    "census.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- age: integer (nullable = true)\n",
      " |-- workclass: string (nullable = true)\n",
      " |-- fnlwgt: integer (nullable = true)\n",
      " |-- education: string (nullable = true)\n",
      " |-- education-num: integer (nullable = true)\n",
      " |-- marital-status: string (nullable = true)\n",
      " |-- occupation: string (nullable = true)\n",
      " |-- relationship: string (nullable = true)\n",
      " |-- race: string (nullable = true)\n",
      " |-- sex: string (nullable = true)\n",
      " |-- capital-gain: integer (nullable = true)\n",
      " |-- capital-loss: integer (nullable = true)\n",
      " |-- hours-per-week: integer (nullable = true)\n",
      " |-- native-country: string (nullable = true)\n",
      " |-- label: string (nullable = true)"
     ]
    }
   ],
   "source": [
    "census.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data prep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List of columns to keep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['label', 'age', 'capital-gain', 'capital-loss', 'hours-per-week', 'workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'native-country']"
     ]
    }
   ],
   "source": [
    "cols_to_keep = census.dtypes\n",
    "\n",
    "cols_to_keep = (\n",
    "    ['label','age'\n",
    "     ,'capital-gain'\n",
    "     ,'capital-loss'\n",
    "     ,'hours-per-week'\n",
    "    ] + [\n",
    "        e[0] for e in cols_to_keep[:-1] \n",
    "        if e[1] == 'string'\n",
    "    ]\n",
    ")\n",
    "\n",
    "cols_to_keep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get numeric and categorical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(['age', 'capital-gain', 'capital-loss', 'hours-per-week'], ['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'native-country'])"
     ]
    }
   ],
   "source": [
    "import pyspark.mllib.stat as st\n",
    "import numpy as np\n",
    "\n",
    "census_subset = census.select(cols_to_keep)\n",
    "\n",
    "cols_num = [\n",
    "    e[0] for e in census_subset.dtypes \n",
    "    if e[1] == 'int'\n",
    "]\n",
    "cols_cat = [\n",
    "    e[0] for e in census_subset.dtypes[1:] \n",
    "    if e[1] == 'string'\n",
    "]\n",
    "cols_num, cols_cat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numerical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age: min->17.0, mean->38.6, max->90.0, stdev->13.6\n",
      "capital-gain: min->0.0, mean->1077.6, max->99999.0, stdev->7385.3\n",
      "capital-loss: min->0.0, mean->87.3, max->4356.0, stdev->403.0\n",
      "hours-per-week: min->1.0, mean->40.4, max->99.0, stdev->12.3"
     ]
    }
   ],
   "source": [
    "rdd_num = (\n",
    "    census_subset\n",
    "    .select(cols_num)\n",
    "    .rdd\n",
    "    .map(lambda row: [e for e in row])\n",
    ")\n",
    "\n",
    "stats_num = st.Statistics.colStats(rdd_num)\n",
    "\n",
    "for col, min_, mean_, max_, var_ in zip(\n",
    "      cols_num\n",
    "    , stats_num.min()\n",
    "    , stats_num.mean()\n",
    "    , stats_num.max()\n",
    "    , stats_num.variance()\n",
    "):\n",
    "    print('{0}: min->{1:.1f}, mean->{2:.1f}, max->{3:.1f}, stdev->{4:.1f}'\n",
    "          .format(col, min_, mean_, max_, np.sqrt(var_)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sex [('Male', 21790), ('Female', 10771)] \n",
      "\n",
      "race [('White', 27816), ('Black', 3124), ('Asian-Pac-Islander', 1039), ('Amer-Indian-Eskimo', 311), ('Other', 271)] \n",
      "\n",
      "label [('<=50K', 24720), ('>50K', 7841)] \n",
      "\n",
      "native-country [('United-States', 29170), ('Mexico', 643), ('?', 583), ('Philippines', 198), ('Germany', 137), ('Canada', 121), ('Puerto-Rico', 114), ('El-Salvador', 106), ('India', 100), ('Cuba', 95), ('England', 90), ('Jamaica', 81), ('South', 80), ('China', 75), ('Italy', 73), ('Dominican-Republic', 70), ('Vietnam', 67), ('Guatemala', 64), ('Japan', 62), ('Poland', 60), ('Columbia', 59), ('Taiwan', 51), ('Haiti', 44), ('Iran', 43), ('Portugal', 37), ('Nicaragua', 34), ('Peru', 31), ('France', 29), ('Greece', 29), ('Ecuador', 28), ('Ireland', 24), ('Hong', 20), ('Trinadad&Tobago', 19), ('Cambodia', 19), ('Laos', 18), ('Thailand', 18), ('Yugoslavia', 16), ('Outlying-US(Guam-USVI-etc)', 14), ('Hungary', 13), ('Honduras', 13), ('Scotland', 12), ('Holand-Netherlands', 1)] \n",
      "\n",
      "marital-status [('Married-civ-spouse', 14976), ('Never-married', 10683), ('Divorced', 4443), ('Separated', 1025), ('Widowed', 993), ('Married-spouse-absent', 418), ('Married-AF-spouse', 23)] \n",
      "\n",
      "workclass [('Private', 22696), ('Self-emp-not-inc', 2541), ('Local-gov', 2093), ('?', 1836), ('State-gov', 1298), ('Self-emp-inc', 1116), ('Federal-gov', 960), ('Without-pay', 14), ('Never-worked', 7)] \n",
      "\n",
      "education [('HS-grad', 10501), ('Some-college', 7291), ('Bachelors', 5355), ('Masters', 1723), ('Assoc-voc', 1382), ('11th', 1175), ('Assoc-acdm', 1067), ('10th', 933), ('7th-8th', 646), ('Prof-school', 576), ('9th', 514), ('12th', 433), ('Doctorate', 413), ('5th-6th', 333), ('1st-4th', 168), ('Preschool', 51)] \n",
      "\n",
      "occupation [('Prof-specialty', 4140), ('Craft-repair', 4099), ('Exec-managerial', 4066), ('Adm-clerical', 3770), ('Sales', 3650), ('Other-service', 3295), ('Machine-op-inspct', 2002), ('?', 1843), ('Transport-moving', 1597), ('Handlers-cleaners', 1370), ('Farming-fishing', 994), ('Tech-support', 928), ('Protective-serv', 649), ('Priv-house-serv', 149), ('Armed-Forces', 9)] \n",
      "\n",
      "relationship [('Husband', 13193), ('Not-in-family', 8305), ('Own-child', 5068), ('Unmarried', 3446), ('Wife', 1568), ('Other-relative', 981)]"
     ]
    }
   ],
   "source": [
    "rdd_cat = (\n",
    "    census_subset\n",
    "    .select(cols_cat + ['label'])\n",
    "    .rdd\n",
    "    .map(lambda row: [e for e in row])\n",
    ")\n",
    "\n",
    "results_cat = {}\n",
    "\n",
    "for i, col in enumerate(cols_cat + ['label']):\n",
    "    results_cat[col] = (\n",
    "        rdd_cat\n",
    "        .groupBy(lambda row: row[i])\n",
    "        .map(lambda el: (el[0], len(el[1])))\n",
    "        .collect()\n",
    "    )\n",
    "\n",
    "for k in results_cat:\n",
    "    print(\n",
    "        k\n",
    "        , sorted(\n",
    "            results_cat[k]\n",
    "            , key=lambda el: el[1]\n",
    "            , reverse=True)\n",
    "        , '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array([[ 1.        ,  0.0776745 ,  0.05777454,  0.06875571],\n",
      "       [ 0.0776745 ,  1.        , -0.03161506,  0.07840862],\n",
      "       [ 0.05777454, -0.03161506,  1.        ,  0.05425636],\n",
      "       [ 0.06875571,  0.07840862,  0.05425636,  1.        ]])"
     ]
    }
   ],
   "source": [
    "correlations = st.Statistics.corr(rdd_num)\n",
    "correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age\n",
      "     capital-gain 0.077674498166\n",
      "     capital-loss 0.057774539479\n",
      "     hours-per-week 0.0687557075095\n",
      "\n",
      "capital-gain\n",
      "     age 0.077674498166\n",
      "     hours-per-week 0.0784086153901\n",
      "\n",
      "capital-loss\n",
      "     age 0.057774539479\n",
      "     hours-per-week 0.0542563622727\n",
      "\n",
      "hours-per-week\n",
      "     age 0.0687557075095\n",
      "     capital-gain 0.0784086153901\n",
      "     capital-loss 0.0542563622727"
     ]
    }
   ],
   "source": [
    "for i, el_i in enumerate(abs(correlations) > 0.05):\n",
    "    print(cols_num[i])\n",
    "    \n",
    "    for j, el_j in enumerate(el_i):\n",
    "        if el_j and j != i:\n",
    "            print(\n",
    "                '    '\n",
    "                , cols_num[j]\n",
    "                , correlations[i][j]\n",
    "            )\n",
    "            \n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistical testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "the occurrence of the outcomes is statistically independent."
     ]
    }
   ],
   "source": [
    "import pyspark.mllib.linalg as ln\n",
    "\n",
    "census_occupation = (\n",
    "    census\n",
    "    .groupby('occupation')\n",
    "    .pivot('label')\n",
    "    .count()\n",
    ")\n",
    "\n",
    "census_occupation_coll = (\n",
    "    census_occupation\n",
    "    .rdd\n",
    "    .map(lambda row: (row[1:]))\n",
    "    .flatMap(lambda row: row)\n",
    "    .collect()\n",
    ")\n",
    "\n",
    "len_row = len(census_occupation.collect())\n",
    "dense_mat = ln.DenseMatrix(\n",
    "    len_row\n",
    "    , 2\n",
    "    , census_occupation_coll\n",
    "    , True\n",
    ")\n",
    "\n",
    "chi_sq = st.Statistics.chiSqTest(dense_mat)\n",
    "\n",
    "print(chi_sq.pValue)\n",
    "print(chi_sq.nullHypothesis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array([[  2.66700000e+03,   9.83000000e+02],\n",
      "       [  2.09800000e+03,   1.96800000e+03],\n",
      "       [  2.28100000e+03,   1.85900000e+03],\n",
      "       [  1.28400000e+03,   8.60000000e+01],\n",
      "       [  8.79000000e+02,   1.15000000e+02],\n",
      "       [  3.17000000e+03,   9.29000000e+02],\n",
      "       [  1.27700000e+03,   3.20000000e+02],\n",
      "       [  1.48000000e+02,   1.00000000e+00],\n",
      "       [  4.38000000e+02,   2.11000000e+02],\n",
      "       [  3.15800000e+03,   1.37000000e+02],\n",
      "       [  6.45000000e+02,   2.83000000e+02],\n",
      "       [  1.75200000e+03,   2.50000000e+02],\n",
      "       [  8.00000000e+00,   1.00000000e+00],\n",
      "       [  1.65200000e+03,   1.91000000e+02],\n",
      "       [  3.26300000e+03,   5.07000000e+02]])"
     ]
    }
   ],
   "source": [
    "dense_mat.toArray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transforming the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of distinct values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len_ftrs = []\n",
    "\n",
    "for col in cols_to_keep[5:]:\n",
    "    (\n",
    "        len_ftrs\n",
    "        .append(\n",
    "            (col\n",
    "             , census\n",
    "                 .select(col)\n",
    "                 .distinct()\n",
    "                 .count()\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    \n",
    "len_ftrs = dict(len_ftrs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using hashing trick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pyspark.mllib.feature as feat\n",
    "\n",
    "final_data = (\n",
    "    census\n",
    "    .select(cols_to_keep)\n",
    "    .rdd\n",
    "    .map(lambda row: [\n",
    "        list(\n",
    "            feat.HashingTF(int(len_ftrs[col] / 2.0))\n",
    "            .transform(row[i])\n",
    "            .toArray()\n",
    "        ) if i > 4\n",
    "        else [row[i]] \n",
    "        for i, col in enumerate(cols_to_keep)]\n",
    "    )\n",
    ")\n",
    "\n",
    "final_data.take(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encode label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def labelEncode(label):\n",
    "    return [int(label[0] == '>50K')]\n",
    "\n",
    "final_data = (\n",
    "    final_data\n",
    "    .map(lambda row: labelEncode(row[0]) \n",
    "         + [item \n",
    "            for sublist in row[1:] \n",
    "            for item in sublist]\n",
    "        )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating an RDD for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.mllib.feature as ft\n",
    "import pyspark.mllib.linalg as ln\n",
    "import pyspark.mllib.regression as reg\n",
    "\n",
    "final_data_income = (\n",
    "    final_data\n",
    "    .map(lambda row: reg.LabeledPoint(\n",
    "        row[0]\n",
    "        , ln.Vectors.dense(row[1:]))\n",
    "        )\n",
    ")\n",
    "final_data_income.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data_hours = (\n",
    "    final_data\n",
    "    .map(lambda row: reg.LabeledPoint(\n",
    "        row[4]\n",
    "        , ln.Vectors.dense(row[0:4] + row[5:]))\n",
    "        )\n",
    ")\n",
    "final_data_hours.take(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting hours of work for census respondents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get some testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_data_reg=sc.parallelize(final_data_hours.take(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear regression (benchmark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workhours_model_lm = reg.LinearRegressionWithSGD.train(\n",
    "    final_data_hours\n",
    "    , iterations = 10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t,p in zip(\n",
    "    test_data_reg\n",
    "        .map(lambda row: row.label)\n",
    "        .collect()\n",
    "    , workhours_model_lm.predict(\n",
    "        test_data_reg\n",
    "            .map(lambda row: row.features)\n",
    "    ).collect()):\n",
    "    print(t,p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forecasting income levels of census respondents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get some testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_data_class=sc.parallelize(final_data_income.take(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.mllib.classification as cl\n",
    "\n",
    "income_model_lr = cl.LogisticRegressionWithSGD.train(\n",
    "    final_data_income\n",
    "    , iterations=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t,p in zip(\n",
    "    test_data_class\n",
    "        .map(lambda row: row.label)\n",
    "        .collect()\n",
    "    , income_model_lr.predict(\n",
    "        test_data_class\n",
    "            .map(lambda row: row.features)\n",
    "    ).collect()):\n",
    "    print(t,p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "income_model_lr.threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "income_model_lr.weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "income_model_svm = cl.SVMWithSGD.train(\n",
    "    final_data_income\n",
    "    , iterations=100\n",
    "    , step=0.98\n",
    "    , miniBatchFraction=1/3.0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t,p in zip(\n",
    "    test_data_class\n",
    "        .map(lambda row: row.label)\n",
    "        .collect()\n",
    "    , income_model_svm.predict(\n",
    "        test_data_class\n",
    "            .map(lambda row: row.features)\n",
    "    ).collect()):\n",
    "    print(t,p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "income_model_svm.weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building clustering models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pyspark.mllib.clustering as clu\n",
    "\n",
    "model = clu.KMeans.train(\n",
    "    final_data.map(lambda row: row[1:])\n",
    "    , 2\n",
    "    , maxIterations=10\n",
    "    , initializationMode='random'\n",
    "    , seed=666\n",
    "    , initializationSteps=5\n",
    "    , epsilon=1e-4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.metrics as m\n",
    "\n",
    "predicted = (\n",
    "    model\n",
    "        .predict(\n",
    "            final_data.map(lambda row: row[1:])\n",
    "        )\n",
    ")\n",
    "predicted = predicted.collect()\n",
    "\n",
    "true = final_data.map(lambda row: row[0]).collect()\n",
    "\n",
    "print(m.homogeneity_score(true, predicted))\n",
    "print(m.completeness_score(true, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computing performance statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pyspark.mllib.evaluation as ev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Regression metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "true_pred_reg = (\n",
    "    final_data_hours\n",
    "    .map(lambda row: (\n",
    "         float(workhours_model_lm.predict(row.features))\n",
    "         , row.label))\n",
    ")\n",
    "\n",
    "metrics_lm = ev.RegressionMetrics(true_pred_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('R^2: ', metrics_lm.r2)\n",
    "print('Explained Variance: ', metrics_lm.explainedVariance)\n",
    "print('meanAbsoluteError: ', metrics_lm.meanAbsoluteError)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_pred_class_lr = (\n",
    "    final_data_income\n",
    "    .map(lambda row: (\n",
    "        float(income_model_lr.predict(row.features))\n",
    "        , row.label))\n",
    ")\n",
    "\n",
    "metrics_lr = ev.BinaryClassificationMetrics(true_pred_class_lr)\n",
    "\n",
    "print('areaUnderPR: ', metrics_lr.areaUnderPR)\n",
    "print('areaUnderROC: ', metrics_lr.areaUnderPR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainErr = (\n",
    "    true_pred_class_lr\n",
    "    .filter(lambda lp: lp[0] != lp[1]).count() \n",
    "    / float(true_pred_class_lr.count())\n",
    ")\n",
    "print(\"Training Error = \" + str(trainErr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_pred_class_svm = (\n",
    "    final_data_income\n",
    "    .map(lambda row: (\n",
    "        float(income_model_svm.predict(row.features))\n",
    "        , row.label))\n",
    ")\n",
    "\n",
    "metrics_svm = ev.BinaryClassificationMetrics(true_pred_class_svm)\n",
    "\n",
    "print('areaUnderPR: ', metrics_svm.areaUnderPR)\n",
    "print('areaUnderROC: ', metrics_svm.areaUnderPR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainErr = (\n",
    "    true_pred_class_svm\n",
    "    .filter(lambda lp: lp[0] != lp[1]).count() \n",
    "    / float(true_pred_class_svm.count())\n",
    ")\n",
    "\n",
    "print(\"Training Error = \" + str(trainErr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    true_pred_class_svm\n",
    "    .map(lambda el: ((el), 1))\n",
    "    .reduceByKey(lambda x,y: x+y)\n",
    "    .take(4)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    true_pred_class_lr\n",
    "    .map(lambda el: ((el), 1))\n",
    "    .reduceByKey(lambda x,y: x+y)\n",
    "    .take(4)\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 2
   },
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
